{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. The USIDataset\n",
    "================================================================================\n",
    "\n",
    "**Suhas Somnath**\n",
    "\n",
    "11/11/2017\n",
    "\n",
    "**This document illustrates how the pyUSID.USIDataset class substantially simplifies accessing information about,\n",
    "slicing, and visualizing N-dimensional Universal Spectroscopy and Imaging Data (USID) Main datasets**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USID Main Datasets\n",
    "------------------\n",
    "According to the **Universal Spectroscopy and Imaging Data (USID)** model, all spatial dimensions are collapsed to a\n",
    "single dimension and, similarly, all spectroscopic dimensions\n",
    "are also collapsed to a single dimension. Thus, the data is stored as a two-dimensional (N x P) matrix with N spatial\n",
    "locations each with P spectroscopic data points.\n",
    "\n",
    "This general and intuitive format allows imaging data from any instrument, measurement scheme, size, or dimensionality\n",
    "to be represented in the same way. Such an instrument independent data format enables a single set of analysis and\n",
    "processing functions to be reused for multiple image formats or modalities.\n",
    "\n",
    "``Main datasets`` are greater than the sum of their parts. They are more capable and information-packed than\n",
    "conventional datasets since they have (or are linked to) all the necessary information to describe a measured dataset.\n",
    "The additional information contained / linked by ``Main datasets`` includes:\n",
    "\n",
    "* the recorded physical quantity\n",
    "* units of the data\n",
    "* names of the position and spectroscopic dimensions\n",
    "* dimensionality of the data in its original N dimensional form etc.\n",
    "\n",
    "USIDatasets = USID Main Datasets\n",
    "--------------------------------\n",
    "Regardless, ``Main datasets`` are just concepts or blueprints and not concrete digital objects in a programming language\n",
    "or a file. ``USIDatasets`` are **tangible representations of Main datasets**. From an implementation perspective, the\n",
    "USIDataset class extends the ``h5py.Dataset object``. In other words, USIDatasets have all the capabilities of\n",
    "standard HDF5 / h5py Dataset objects but are supercharged from a scientific perspective since they:\n",
    "\n",
    "* are self-describing\n",
    "* allow quick interactive visualization in Jupyter notebooks\n",
    "* allow intuitive slicing of the N dimensional dataset\n",
    "* and much much more.\n",
    "\n",
    "While it is most certainly possible to access this information and enable these functionalities via the native ``h5py``\n",
    "functionality, it can become tedious very quickly.  In fact, a lot of the functionality of USIDataset comes from\n",
    "orchestration of multiple functions in ``pyUSID.hdf_utils`` outlined in other documents. The USIDataset class\n",
    "makes such necessary information and functionality easily accessible.\n",
    "\n",
    "Since Main datasets are the hubs of information in a USID HDF5 file (**h5USID**), we expect that the majority of\n",
    "the data interrogation will happen via USIDatasets\n",
    "\n",
    "Recommended pre-requisite reading\n",
    "---------------------------------\n",
    "* `USID data model </../../data_format.html>`_\n",
    "* `Crash course on HDF5 and h5py <./plot_h5py.html>`_\n",
    "* Utilities for `reading <./plot_hdf_utils_read.html>`_ h5USID files\n",
    "  h5USID files using pyUSID\n",
    "\n",
    "Example scientific dataset\n",
    "---------------------------\n",
    "\n",
    "Before, we dive into the functionalities of USIDatasets we need to understand the dataset that will be used in this\n",
    "example. For this example, we will be working with a Band Excitation Polarization Switching (BEPS) dataset acquired\n",
    "from advanced atomic force microscopes. In the much simpler Band Excitation (BE) imaging datasets, a single spectra\n",
    "is acquired at each location in a two dimensional grid of spatial locations. Thus, BE imaging datasets have two\n",
    "position dimensions (X, Y) and one spectroscopic dimension (frequency - against which the spectra is recorded). The\n",
    "BEPS dataset used in this example has a spectra for each combination of three other parameters (DC offset, Field, and\n",
    "Cycle). Thus, this dataset has three new spectral dimensions in addition to the spectra itself. Hence, this dataset\n",
    "becomes a 2+4 = 6 dimensional dataset\n",
    "\n",
    ".. tip::\n",
    "    You can download and run this document as a Jupyter notebook using the link at the bottom of this page.\n",
    "\n",
    "Load all necessary packages\n",
    "---------------------------\n",
    "\n",
    "First, we need to load the necessary packages. Here are a list of packages, besides pyUSID, that will be used in\n",
    "this example:\n",
    "\n",
    "* ``h5py`` - to open and close the file\n",
    "* ``numpy`` - for numerical operations on arrays in memory\n",
    "* ``matplotlib`` - basic visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import os\n",
    "# Warning package in case something goes wrong\n",
    "from warnings import warn\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "# Package for downloading online files:\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import pyUSID as usid\n",
    "except ImportError:\n",
    "    warn('pyUSID not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install('pyUSID')\n",
    "    import pyUSID as usid\n",
    "    \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets open this HDF5 file in read-only mode. Note that opening the file does not cause the contents to be\n",
    "automatically loaded to memory. Instead, we are presented with objects that refer to specific HDF5 datasets,\n",
    "attributes or groups in the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = './data/BEPS_small.h5'\n",
    "h5_f = h5py.File(h5_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ``h5_f`` is an active handle to the open file.\n",
    "Lets quickly look at the contents of this HDF5 file using a handy function in ``pyUSID.hdf_utils`` - ``print_tree()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Contents of the H5 file:')\n",
    "usid.hdf_utils.print_tree(h5_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will only focus on the ``Raw_Data`` dataset which contains the 6D raw measurement data. First lets\n",
    "access the HDF5 dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_raw = usid.USIDataset(h5_f['/Measurement_000/Channel_000/Raw_Data'])\n",
    "print(pd_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How USIDataset simplifies data handling:\n",
    "======================\n",
    "\n",
    "## 1. Reference Values for each Dimension\n",
    "When visualizing the data it is essential to plot the data against appropriate values on the X, Y, Z axes. The\n",
    "USIDataset object makes it very easy to access the values over which a dimension was varied using the\n",
    "``get_pos_values()`` and ``get_spec_values()`` functions. This functionality is enabled by the ``get_unit_values()``\n",
    "function in ``pyUSID.hdf_utils``.\n",
    "\n",
    "For example, let us say we wanted to see how the ``DC_Offset`` dimension was varied, we could:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = 'DC_Offset'\n",
    "\n",
    "dc_vec = pd_raw.get_spec_values(dim_name)\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(5, 5))\n",
    "axis.plot(dc_vec, '*-')\n",
    "axis.set_xlabel('Points in dimension', fontsize=18)\n",
    "axis.set_ylabel('Values over which\\nparameter was varied', fontsize=18)\n",
    "axis.set_title(dim_name, fontsize=18)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reshaping to N dimensions\n",
    "The USID model stores N dimensional datasets in a flattened 2D form of position x spectral values. It can become\n",
    "challenging to retrieve the data in its original N-dimensional form, especially for multidimensional datasets\n",
    "such as the one we are working on. Fortunately, all the information regarding the dimensionality of the dataset\n",
    "are contained in the spectral and position ancillary datasets. PycoDataset makes it remarkably easy to obtain the N\n",
    "dimensional form of a dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nShape of dataset as it is stored in the HDF5 file: {}\\n'.format(pd_raw.shape))\n",
    "\n",
    "ndim_form = pd_raw.get_n_dim_form()\n",
    "\n",
    "print('Shape of the N dimensional form of the dataset:')\n",
    "print(ndim_form.shape)\n",
    "print('And these are the dimensions')\n",
    "print(pd_raw.n_dim_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing / Slicing with words\n",
    "It is often very challenging to grapple with multidimensional datasets such as the one in this example. It may not\n",
    "even be possible to load the entire dataset in its 2D or N dimensional form to memory if the dataset is several (or\n",
    "several hundred) gigabytes large. **Slicing the 2D Main dataset can easily become confusing and frustrating**. \n",
    "\n",
    "The hard was is to:\n",
    "* Load the entire dataset from the file to memory. **What if the dataset is too large to load into memory**\n",
    "* Reshape it to its N-dimensional form\n",
    "* Figure out which dimension corresponds to which index in the N-dimensional dataset\n",
    "* Finally slice it\n",
    "\n",
    "Let's say we want to get the spatial map for:\n",
    "* 14th index of DC Offset\n",
    "* 1st index of cycle\n",
    "* 0th index of Field (remember Python is 0 based)\n",
    "* 43rd index of Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortunately, this dataset is tiny and we already have the data in its N-dimensional form already!\n",
    "spat_map_2 = np.squeeze(ndim_form[:, :, 43, 14, 0, 1])\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(5, 5))\n",
    "axis.imshow(np.squeeze(np.abs(spat_map_2)))\n",
    "axis.set_xlabel('X', fontsize=18)\n",
    "axis.set_ylabel('Y', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve\n",
    "this problem, USIDataset has a ``slice()`` function that efficiently loads the only the sliced data into memory and\n",
    "reshapes the data to an N dimensional form. Best of all, the slicing arguments can be provided in the actual\n",
    "N dimensional form!\n",
    "\n",
    "With the USIDataset we:\n",
    "* Do not need to load the entire dataset to memory\n",
    "* Can slice by addressing dimensions by their name without having to worry about the actual order of the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We slice directly on the USIDataset in ONE line!:\n",
    "spat_map_1, success = pd_raw.slice({'Frequency': 43, 'DC_Offset': 14, 'Field': 0, 'Cycle': 1})\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(5, 5))\n",
    "axis.imshow(np.squeeze(np.abs(spat_map_1)))\n",
    "axis.set_xlabel('X', fontsize=18)\n",
    "axis.set_ylabel('Y', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Visualization\n",
    "### Works best on Google Chrome and not so well on Internet Explorer, Safari or Firefox\n",
    "USIDatasets also enable quick, interactive, and easy visualization of data up to 2 position and 2 spectroscopic\n",
    "dimensions (4D datasets). Since this particular example has 6 dimensions, we would need to slice two dimensions in\n",
    "order to visualize the remaining 4 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_raw.visualize(slice_dict={'Field': 0, 'Cycle': 1});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the h5_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
